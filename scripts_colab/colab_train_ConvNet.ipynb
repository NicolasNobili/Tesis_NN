{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1225,"status":"ok","timestamp":1748807972371,"user":{"displayName":"Nicolas Nobili","userId":"17230013244848673171"},"user_tz":180},"id":"HpomfX25xykJ","outputId":"c06f6d60-01ee-45c4-d3a3-4cc65ef7d2dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Drive montado. Carpeta repo seteada en: /content/drive/MyDrive/Tesis/Tesis_NN\n"]}],"source":["from google.colab import drive\n","import sys\n","import os\n","\n","# Montar Google Drive\n","drive.mount('/content/drive')\n","\n","# Definir rutas base y repo\n","BASE_PATH = '/content/drive/MyDrive/Tesis'\n","REPO_NAME = 'Tesis_NN'\n","REPO_PATH = os.path.join(BASE_PATH, REPO_NAME)\n","\n","# Agregar repo al path de Python para imports\n","if REPO_PATH not in sys.path:\n","    sys.path.append(REPO_PATH)\n","\n","# Cambiar directorio actual al repo (para comandos git)\n","os.chdir(REPO_PATH)\n","\n","print(f\"Drive montado. Carpeta repo seteada en: {REPO_PATH}\")"]},{"cell_type":"code","source":["from google.colab import files\n","%cd /content/drive/MyDrive/Tesis/Tesis_NN\n","!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1VfCcaSOEF7M","executionInfo":{"status":"ok","timestamp":1748808008833,"user_tz":180,"elapsed":5629,"user":{"displayName":"Nicolas Nobili","userId":"17230013244848673171"}},"outputId":"a385a00c-ad96-4138-994c-41c9e497a66c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Collecting asttokens==3.0.0 (from -r requirements.txt (line 1))\n","  Using cached asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n","Collecting braceexpand==0.1.7 (from -r requirements.txt (line 2))\n","  Using cached braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: certifi==2025.4.26 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2025.4.26)\n","Collecting colorama==0.4.6 (from -r requirements.txt (line 4))\n","  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Collecting comm==0.2.2 (from -r requirements.txt (line 5))\n","  Using cached comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: contourpy==1.3.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.3.2)\n","Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.12.1)\n","Collecting debugpy==1.8.14 (from -r requirements.txt (line 8))\n","  Using cached debugpy-1.8.14-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n","Collecting decorator==5.2.1 (from -r requirements.txt (line 9))\n","  Using cached decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n","Collecting executing==2.2.0 (from -r requirements.txt (line 10))\n","  Using cached executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\n","Requirement already satisfied: filelock==3.18.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (3.18.0)\n","Collecting fonttools==4.58.1 (from -r requirements.txt (line 12))\n","  Using cached fonttools-4.58.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (106 kB)\n","Collecting fsspec==2025.5.1 (from -r requirements.txt (line 13))\n","  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: geopandas==1.0.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (1.0.1)\n","Collecting ipykernel==6.29.5 (from -r requirements.txt (line 15))\n","  Using cached ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n","Collecting ipython==9.3.0 (from -r requirements.txt (line 16))\n","  Using cached ipython-9.3.0-py3-none-any.whl.metadata (4.4 kB)\n","Collecting ipython_pygments_lexers==1.1.1 (from -r requirements.txt (line 17))\n","  Using cached ipython_pygments_lexers-1.1.1-py3-none-any.whl.metadata (1.1 kB)\n","Collecting jedi==0.19.2 (from -r requirements.txt (line 18))\n","  Using cached jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: Jinja2==3.1.6 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (3.1.6)\n","Collecting jupyter_client==8.6.3 (from -r requirements.txt (line 20))\n","  Using cached jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n","Collecting jupyter_core==5.8.1 (from -r requirements.txt (line 21))\n","  Using cached jupyter_core-5.8.1-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: kiwisolver==1.4.8 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (1.4.8)\n","Requirement already satisfied: MarkupSafe==3.0.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 23)) (3.0.2)\n","Collecting matplotlib==3.10.3 (from -r requirements.txt (line 24))\n","  Using cached matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: matplotlib-inline==0.1.7 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (0.1.7)\n","Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (1.3.0)\n","Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (1.6.0)\n","Collecting networkx==3.5 (from -r requirements.txt (line 28))\n","  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n","Collecting numpy==2.2.6 (from -r requirements.txt (line 29))\n","  Using cached numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n","Collecting packaging==25.0 (from -r requirements.txt (line 30))\n","  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n","Collecting pandas==2.2.3 (from -r requirements.txt (line 31))\n","  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n","Requirement already satisfied: parso==0.8.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 32)) (0.8.4)\n","Requirement already satisfied: pillow==11.2.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 33)) (11.2.1)\n","Requirement already satisfied: platformdirs==4.3.8 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 34)) (4.3.8)\n","Requirement already satisfied: prompt_toolkit==3.0.51 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 35)) (3.0.51)\n","Collecting psutil==7.0.0 (from -r requirements.txt (line 36))\n","  Using cached psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n","Collecting pure_eval==0.2.3 (from -r requirements.txt (line 37))\n","  Using cached pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n","Requirement already satisfied: Pygments==2.19.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 38)) (2.19.1)\n","Requirement already satisfied: pyogrio==0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 39)) (0.11.0)\n","Requirement already satisfied: pyparsing==3.2.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 40)) (3.2.3)\n","Requirement already satisfied: pyproj==3.7.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 41)) (3.7.1)\n","Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (2.9.0.post0)\n","Requirement already satisfied: pytz==2025.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 43)) (2025.2)\n","\u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pywin32==310 (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for pywin32==310\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install webdataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yR34MitpFxA-","executionInfo":{"status":"ok","timestamp":1748808184298,"user_tz":180,"elapsed":2519,"user":{"displayName":"Nicolas Nobili","userId":"17230013244848673171"}},"outputId":"5ac9a919-5d68-440e-a5bf-ded092ee1942"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting webdataset\n","  Downloading webdataset-0.2.111-py3-none-any.whl.metadata (15 kB)\n","Collecting braceexpand (from webdataset)\n","  Using cached braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from webdataset) (2.0.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from webdataset) (6.0.2)\n","Downloading webdataset-0.2.111-py3-none-any.whl (85 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n","Installing collected packages: braceexpand, webdataset\n","Successfully installed braceexpand-0.1.7 webdataset-0.2.111\n"]}]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":1876,"status":"ok","timestamp":1748808200321,"user":{"displayName":"Nicolas Nobili","userId":"17230013244848673171"},"user_tz":180},"id":"wEswSVb9yfbG"},"outputs":[],"source":["# ───────────────────────────────────────────────────────────────────────────────\n","# 📦 Standard Library Imports\n","# ───────────────────────────────────────────────────────────────────────────────\n","import os\n","import sys\n","import time\n","import csv\n","import json\n","from pathlib import Path\n","\n","# ───────────────────────────────────────────────────────────────────────────────\n","# 📚 Scientific & Data Libraries\n","# ───────────────────────────────────────────────────────────────────────────────\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# ───────────────────────────────────────────────────────────────────────────────\n","# 🌍 Third-Party Library Imports (PyTorch)\n","# ───────────────────────────────────────────────────────────────────────────────\n","import torch\n","import torch.optim as optim\n","\n","# ───────────────────────────────────────────────────────────────────────────────\n","# 🧩 Custom Project Modules\n","# ───────────────────────────────────────────────────────────────────────────────\n","sys.path.append('C:/Users/nnobi/Desktop/FIUBA/Tesis/Project')\n","\n","from project_package.utils import train_common_routines as tcr\n","from project_package.conv_net.ConvNet_model import SRCNN\n","from project_package.dataset_manager.webdataset_dataset import PtWebDataset\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":75,"status":"error","timestamp":1748808203275,"user":{"displayName":"Nicolas Nobili","userId":"17230013244848673171"},"user_tz":180},"id":"5CYJUmCuzCvb","outputId":"13267beb-60d6-46fd-c0c4-1e7dcd045ae4"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name '__file__' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-e11f9fecd730>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 📁 Paths Setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# ───────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mscript_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mproject_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"]}],"source":["# ───────────────────────────────────────────────────────────────────────────────\n","# 🔧 Configuration\n","# ───────────────────────────────────────────────────────────────────────────────\n","model_selection = 'large'\n","epochs = 200\n","lr = 1e-5\n","batch_size = 32\n","\n","# ───────────────────────────────────────────────────────────────────────────────\n","# 📁 Paths Setup\n","# ───────────────────────────────────────────────────────────────────────────────\n","script_dir = os.path.dirname(os.path.abspath(__file__))\n","project_dir = os.path.abspath(os.path.join(script_dir, '..'))\n","\n","dataset = 'messi' # Select Dataset\n","dataset_folder = os.path.join(project_dir, 'datasets', dataset)\n","tar_path = \"file:\" + dataset_folder.replace(\"\\\\\", \"/\")\n","metadata_path = os.path.join(dataset_folder, 'metadata.json')\n","\n","with open(metadata_path, \"r\") as f:\n","    metadata = json.load(f)\n","\n","train_samples = metadata[\"splits\"][\"train\"][\"num_samples\"]\n","val_samples = metadata[\"splits\"][\"val\"][\"num_samples\"]\n","test_samples = metadata[\"splits\"][\"test\"][\"num_samples\"]\n","\n","# Results folder and files\n","results_folder = os.path.join(project_dir, 'results', 'Conv_Net')\n","os.makedirs(results_folder, exist_ok=True)\n","\n","loss_png_file = os.path.join(results_folder, f\"loss_lr={lr}_batch_size={batch_size}_model={model_selection}.png\")\n","psnr_png_file = os.path.join(results_folder, f\"psnr_lr={lr}_batch_size={batch_size}_model={model_selection}.png\")\n","final_model_pth_file = os.path.join(results_folder, f\"model_lr={lr}_batch_size={batch_size}_model={model_selection}.pth\")\n","file_training_losses = os.path.join(results_folder, f\"training_losses_lr={lr}_batch_size={batch_size}_model={model_selection}.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yN_2UvdtzEPq"},"outputs":[],"source":["# ───────────────────────────────────────────────────────────────────────────────\n","# 🚀 Training Pipeline\n","# ───────────────────────────────────────────────────────────────────────────────\n","\n","# 🧠 Model Initialization\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device:\", device)\n","\n","model = SRCNN(model_selection).to(device)\n","print(\"The model:\")\n","print(model)\n","\n","model.count_parameters()\n","print(f\"Total Parameters: {model.total_params:,}\")\n","print(f\"Trainable Parameters: {model.trainable_params:,}\")\n","\n","model = tcr.multi_GPU_training(model)\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","# 📊 Dataset and DataLoaders\n","dataset_train = PtWebDataset(tar_path + '/train.tar', length=train_samples, batch_size=batch_size, shuffle_buffer=5 * batch_size)\n","dataset_val = PtWebDataset(tar_path + '/val.tar', length=val_samples, batch_size=batch_size, shuffle_buffer=5 * batch_size)\n","dataset_test = PtWebDataset(tar_path + '/test.tar', length=test_samples, batch_size=batch_size, shuffle_buffer=5 * batch_size)\n","\n","dataloader_train = dataset_train.get_dataloader(num_workers=0)\n","dataloader_val = dataset_val.get_dataloader(num_workers=0)\n","dataloader_test = dataset_test.get_dataloader(num_workers=0)\n","\n","# 🏋️ Training Loop\n","train_loss, val_loss = [], []\n","train_psnr, val_psnr = [], []\n","\n","start = time.time()\n","for epoch in range(epochs):\n","    print(f\"\\nEpoch {epoch + 1} of {epochs}\")\n","\n","    train_epoch_loss, train_epoch_psnr = tcr.train(model, dataloader_train, optimizer, tcr.compute_loss_MSE, device, train_samples)\n","    val_epoch_loss, val_epoch_psnr = tcr.validate(model, dataloader_val, epoch, tcr.compute_loss_MSE, device, val_samples)\n","\n","    print(f\"Train PSNR: {train_epoch_psnr:.3f}\")\n","    print(f\"Val PSNR: {val_epoch_psnr:.3f}\")\n","\n","    train_loss.append(train_epoch_loss)\n","    train_psnr.append(train_epoch_psnr)\n","    val_loss.append(val_epoch_loss)\n","    val_psnr.append(val_epoch_psnr)\n","\n","    if epoch % 5 == 0:\n","        checkpoint_path = os.path.join(results_folder, f\"checkpoint_epoch_{epoch}_lr={lr}_batch_size={batch_size}_model={model_selection}.pth\")\n","        tcr.save_checkpoint(epoch, model, optimizer, train_loss, filename=checkpoint_path)\n","\n","    with open(file_training_losses, mode=\"a\", newline=\"\") as file:\n","        writer = csv.writer(file)\n","        writer.writerow([train_epoch_loss, train_epoch_psnr, val_epoch_loss, val_epoch_psnr])\n","\n","end = time.time()\n","print(f\"\\n✅ Finished training in: {(end - start) / 60:.2f} minutes\")\n","\n","# 📈 Loss Plot\n","plt.figure(figsize=(10, 7))\n","plt.plot(10 * np.log10(train_loss), color='orange', label='Train Loss')\n","plt.plot(10 * np.log10(val_loss), color='red', label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss (dB)')\n","plt.legend()\n","if os.path.exists(loss_png_file):\n","    os.remove(loss_png_file)\n","plt.savefig(loss_png_file)\n","plt.show()\n","\n","# 📈 PSNR Plot\n","plt.figure(figsize=(10, 7))\n","plt.plot(train_psnr, color='green', label='Train PSNR (dB)')\n","plt.plot(val_psnr, color='blue', label='Validation PSNR (dB)')\n","plt.xlabel('Epochs')\n","plt.ylabel('PSNR (dB)')\n","plt.legend()\n","if os.path.exists(psnr_png_file):\n","    os.remove(psnr_png_file)\n","plt.savefig(psnr_png_file)\n","plt.show()\n","\n","# 💾 Save Final Model\n","print('\\n💾 Saving model...')\n","if os.path.exists(final_model_pth_file):\n","    os.remove(final_model_pth_file)\n","model = model.module if hasattr(model, \"module\") else model\n","torch.save(model.state_dict(), final_model_pth_file)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5141,"status":"ok","timestamp":1748488514649,"user":{"displayName":"Nicolas Nobili","userId":"17230013244848673171"},"user_tz":180},"id":"3VAXRuI1z7jI","outputId":"64e244ca-e7e5-4cdb-bb55-c8f3f3e19d7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["The model: \n","SRCNN(\n","  (conv1): Conv2d(3, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=replicate)\n","  (relu1): ReLU(inplace=True)\n","  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=replicate)\n","  (relu2): ReLU(inplace=True)\n","  (conv3): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=replicate)\n","  (relu3): ReLU(inplace=True)\n","  (conv4): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)\n",")\n","Total Parameters: 427,139\n","Trainable Parameters: 427,139\n","Model training to be done in only one GPU!\n","Number of training samples: 123\n","Number of validation samples: 5\n","Number of testing samples: 1\n","Training with unpatched images\n"]}],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}